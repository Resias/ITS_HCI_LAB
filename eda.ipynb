{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fd9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89693d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 201 => 1,2,3,4,9 호선\n",
    "line_1 = [f\"0{num}\" for num in range(150, 160)]\n",
    "line_2 = [f\"0{num}\" for num in range(201, 251)]\n",
    "line_3 = [f\"0{num}\" for num in range(309, 343)]\n",
    "\n",
    "line_4 = [f\"0{num}\" for num in range(409, 435)]\n",
    "line_4.append(\"0405\")\n",
    "line_4.append(\"0406\")\n",
    "line_4.append(\"0408\")\n",
    "line_4 = sorted(set(line_4))\n",
    "\n",
    "\n",
    "# 9호선 일부 205번 코드\n",
    "line_9 = [f\"0{num}\" for num in range(4126, 4139)]   # 201 교통수단 코드\n",
    "for i in range(4101, 4126):                         # 205\n",
    "    line_9.append(f\"0{i}\")\n",
    "line_9 = sorted(set(line_9))\n",
    "\n",
    "names_line_1: List[str] = [\n",
    "    \"서울역\", \"시청\", \"종각\", \"종로3가\", \"종로5가\", \"동대문\", \"신설동\", \"제기동\", \"청량리(지하)\", \"동묘앞\",\n",
    "] \n",
    "names_line_2: List[str] = [\n",
    "    \"시청\", \"을지로입구\", \"을지로3가\", \"을지로4가\", \"동대문역사문화공원\", \"신당\", \"상왕십리\", \"왕십리(성동구청)\",\n",
    "    \"한양대\", \"뚝섬\", \"성수\", \"건대입구\", \"구의\", \"강변\", \"잠실나루\", \"잠실\", \"잠실새내\", \"종합운동장\",\n",
    "    \"삼성\", \"선릉\", \"역삼\", \"강남\", \"교대\", \"서초\", \"방배\", \"사당\", \"낙성대\", \"서울대입구\", \"봉천\",\n",
    "    \"신림\", \"신대방\", \"구로디지털단지\", \"대림\", \"신도림\", \"문래\", \"영등포구청\", \"당산\", \"합정\", \"홍대입구\",\n",
    "    \"신촌\", \"이대\", \"아현\", \"충정로\", \"용답\", \"신답\", \"신설동\", \"도림천\", \"양천구청\", \"신정네거리\", \"용두\"\n",
    "]\n",
    "names_line_3: List[str] = [\n",
    "    \"지축\", \"구파발\", \"연신내\", \"불광\", \"녹번\", \"홍제\", \"무악재\", \"독립문\", \"경복궁\", \"안국\", \"종로3가\",\n",
    "    \"을지로3가\", \"충무로\", \"동대입구\", \"약수\", \"금호\", \"옥수\", \"압구정\", \"신사\", \"잠원\", \"고속터미널\",\n",
    "    \"교대\", \"남부터미널\", \"양재\", \"매봉\", \"도곡\", \"대치\", \"학여울\", \"대청\", \"일원\", \"수서\", \"가락시장\",\n",
    "    \"경찰병원\", \"오금\"\n",
    "]\n",
    "names_line_4: List[str] = [\n",
    "    \"오남\", \"진접\", \"별내별가람\", \"당고개\", \"상계\", \"노원\", \"창동\", \"쌍문\", \"수유(강북구청)\", \"미아\",\n",
    "    \"미아사거리\", \"길음\", \"성신여대입구\", \"한성대입구\", \"혜화\", \"동대문\", \"동대문역사문화공원\", \"충무로\",\n",
    "    \"명동\", \"회현\", \"서울역\", \"숙대입구\", \"삼각지\", \"신용산\", \"이촌\", \"동작\", \"이수\", \"사당\", \"남태령\"\n",
    "]\n",
    "names_line_9: List[str] = [\n",
    "    \"개화\", \"김포공항\", \"공항시장\", \"신방화\", \"마곡나루\", \"양천향교\", \"가양\", \"증미\", \"등촌\", \"염창\",\n",
    "    \"신목동\", \"선유도\", \"당산\", \"국회의사당\", \"여의도\", \"샛강\", \"노량진\", \"노들\", \"흑석(중앙대입구)\",\n",
    "    \"동작\", \"구반포\", \"신반포\", \"고속터미널\", \"사평\", \"신논현\", \"언주\", \"선정릉\", \"삼성중앙\", \"봉은사\",\n",
    "    \"종합운동장\", \"삼전\", \"석촌고분\", \"석촌\", \"송파나루\", \"한성백제\", \"올림픽공원(한국체대)\", \"둔촌오륜\",\n",
    "    \"중앙보훈병원\"\n",
    "]\n",
    "\n",
    "# --- 3) 유틸: 매핑 생성기 + 검증 ---\n",
    "def build_map(codes: List[str], names: List[str]) -> Dict[str, str]:\n",
    "    if len(codes) != len(names):\n",
    "        raise ValueError(f\"코드({len(codes)}) 수와 역명({len(names)}) 수가 다릅니다.\")\n",
    "    # 중복 코드 체크\n",
    "    dup = [c for c in codes if codes.count(c) > 1]\n",
    "    if dup:\n",
    "        raise ValueError(f\"중복 코드 존재: {sorted(set(dup))}\")\n",
    "    # 중복 역명은 허용할 수도 있지만(환승역 등 동일 표기), 필요하면 아래처럼 경고/에러 처리\n",
    "    # dup_names = [n for n in names if names.count(n) > 1]\n",
    "    # if dup_names: print(\"경고: 중복 역명:\", sorted(set(dup_names)))\n",
    "    return dict(zip(codes, names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1345cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) 라인별 딕셔너리 생성 ---\n",
    "map_line_1 = build_map(line_1, names_line_1)\n",
    "map_line_2 = build_map(line_2, names_line_2)\n",
    "map_line_3 = build_map(line_3, names_line_3)\n",
    "map_line_4 = build_map(line_4, names_line_4)\n",
    "map_line_9 = build_map(line_9, names_line_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4602f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0150': '서울역',\n",
       " '0151': '시청',\n",
       " '0152': '종각',\n",
       " '0153': '종로3가',\n",
       " '0154': '종로5가',\n",
       " '0155': '동대문',\n",
       " '0156': '신설동',\n",
       " '0157': '제기동',\n",
       " '0158': '청량리(지하)',\n",
       " '0159': '동묘앞'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_line_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e6d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5) 통합 딕셔너리 (코드 → 역명) ---\n",
    "def merge_maps(*maps: Dict[str, str]) -> Dict[str, str]:\n",
    "    merged: Dict[str, str] = {}\n",
    "    for m in maps:\n",
    "        for k, v in m.items():\n",
    "            if k in merged and merged[k] != v:\n",
    "                # 서로 다른 라인에서 같은 코드가 쓰인다면 충돌. 정책 결정 필요.\n",
    "                raise ValueError(f\"코드 충돌: {k} -> '{merged[k]}' vs '{v}'\")\n",
    "            merged[k] = v\n",
    "    return merged\n",
    "\n",
    "code_to_station = merge_maps(map_line_1, map_line_2, map_line_3, map_line_4, map_line_9)\n",
    "\n",
    "def station_name(code: str) -> str:\n",
    "    return code_to_station.get(code, \"<UNKNOWN>\")\n",
    "\n",
    "def codes_by_station(name: str) -> List[str]:\n",
    "    # 동일 역명이 여러 코드에 매핑될 수 있음(환승역 다중 코드 등)\n",
    "    return [c for c, n in code_to_station.items() if n == name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fab429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "may_path = os.path.join(os.getcwd(),  \"train_pars_final\")\n",
    "data_path_list = [os.path.join(may_path, i)for i in os.listdir(may_path)]\n",
    "one_file_len = 100_000\n",
    "print(len(data_path_list) * one_file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a12bec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tmp = \u001b[43mdata_path_list\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(tmp)\n\u001b[32m      3\u001b[39m data = np.load(tmp, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "tmp = data_path_list[0]\n",
    "print(tmp)\n",
    "data = np.load(tmp, allow_pickle=True)\n",
    "print(data.shape)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447edbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35539, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['user_code', 'Transaction_code', 'InTime','InInformation','OutTime','OutInformation','TransactionID', 'TransferCount'])\n",
    "df_2ndline = df[(df['Transaction_code'].apply(lambda x: x[0] == 201))]\n",
    "df_2ndline_sorted = df_2ndline.sort_values(by=['user_code', 'InTime'], ascending=True)\n",
    "print(df_2ndline.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52133995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          user_code Transaction_code  \\\n",
      "588    KDiZ/m93a16ztIi0+LJ239MNyMTRFqgtpBWPTWVAkj4=    (201, 알 수 없음)   \n",
      "1070   KyZMXbTzgIo2x0VE/ss1qElp2ySidbmgZCMlJ8jXGUk=    (201, 알 수 없음)   \n",
      "1164   JQX1oIlyfv071Wz0iyL4zAZR3Wx0iZWAM4ox4OB6BEw=    (201, 알 수 없음)   \n",
      "1399   KyZaWs6DugnEjuRMrcIHlcQU5rwykFy9APJGBs9xSxU=    (201, 알 수 없음)   \n",
      "1766   LlUwXha7mliZcKGA1VS+YAoc8x3CfJEQ8EAdEiWGr+Q=    (201, 알 수 없음)   \n",
      "...                                             ...              ...   \n",
      "99605  Iz7T68Tkb3Q/QwM4XJg7sCtxRrowIxD1Uy0tjmkDhGw=    (201, 알 수 없음)   \n",
      "99630  ICJHuRsb3O02UiGmR3sOIzFGnr7+rPF3MropNpYHSgM=    (201, 알 수 없음)   \n",
      "99631  ICJHuRsb3O02UiGmR3sOIzFGnr7+rPF3MropNpYHSgM=    (201, 알 수 없음)   \n",
      "99654  IEdIAdvocdlIlWTeoYcPJvrBrOz+/aPuGe5ZQiFZ5+Q=    (201, 알 수 없음)   \n",
      "99910  HTFApO7+M5zIiVGoDJzrY+97zwQa53kLkzuXvsvmops=    (201, 알 수 없음)   \n",
      "\n",
      "                   InTime      InInformation             OutTime  \\\n",
      "588   2022-05-21 06:43:39  (nan, 202, 을지로입구) 2022-05-21 07:44:01   \n",
      "1070  2022-05-21 20:36:26  (nan, 202, 을지로입구) 2022-05-21 21:07:05   \n",
      "1164  2022-05-21 14:50:10  (nan, 202, 을지로입구) 2022-05-21 15:06:14   \n",
      "1399  2022-05-21 21:59:51  (nan, 202, 을지로입구) 2022-05-21 22:49:31   \n",
      "1766  2022-05-21 15:28:37  (nan, 202, 을지로입구) 2022-05-21 15:55:08   \n",
      "...                   ...                ...                 ...   \n",
      "99605 2022-05-21 14:59:22  (nan, 202, 을지로입구) 2022-05-21 16:14:30   \n",
      "99630 2022-05-21 19:03:23  (nan, 202, 을지로입구) 2022-05-21 19:07:00   \n",
      "99631 2022-05-21 19:07:16  (nan, 202, 을지로입구) 2022-05-21 20:35:20   \n",
      "99654 2022-05-21 21:52:50  (nan, 202, 을지로입구) 2022-05-21 22:20:18   \n",
      "99910 2022-05-21 15:10:04  (nan, 202, 을지로입구) 2022-05-21 15:25:04   \n",
      "\n",
      "                OutInformation TransactionID TransferCount  \n",
      "588          (nan, 1208.0, 덕소)             1             1  \n",
      "1070          (nan, 415.0, 미아)             2             0  \n",
      "1164         (nan, 317.0, 경복궁)             1             0  \n",
      "1399         (nan, 1706.0, 안양)             2             0  \n",
      "1766        (nan, 212.0, 건대입구)             2             0  \n",
      "...                        ...           ...           ...  \n",
      "99605        (nan, 1958.0, 대화)             1             0  \n",
      "99630      (nan, 202.0, 을지로입구)             2             0  \n",
      "99631        (nan, 1756.0, 중앙)             3             1  \n",
      "99654       (nan, 2644.0, 돌곶이)             2             0  \n",
      "99910  (nan, 208.0, 왕십리(성동구청))             2             1  \n",
      "\n",
      "[380 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_2ndline_sorted = df_2ndline[df_2ndline['InInformation'].apply(lambda x: x[1] == 202)]\n",
    "print(df_2ndline_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99441c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         user_code Transaction_code  \\\n",
      "588   KDiZ/m93a16ztIi0+LJ239MNyMTRFqgtpBWPTWVAkj4=    (201, 알 수 없음)   \n",
      "1070  KyZMXbTzgIo2x0VE/ss1qElp2ySidbmgZCMlJ8jXGUk=    (201, 알 수 없음)   \n",
      "1164  JQX1oIlyfv071Wz0iyL4zAZR3Wx0iZWAM4ox4OB6BEw=    (201, 알 수 없음)   \n",
      "1399  KyZaWs6DugnEjuRMrcIHlcQU5rwykFy9APJGBs9xSxU=    (201, 알 수 없음)   \n",
      "\n",
      "                  InTime      InInformation             OutTime  \\\n",
      "588  2022-05-21 06:43:39  (nan, 202, 을지로입구) 2022-05-21 07:44:01   \n",
      "1070 2022-05-21 20:36:26  (nan, 202, 을지로입구) 2022-05-21 21:07:05   \n",
      "1164 2022-05-21 14:50:10  (nan, 202, 을지로입구) 2022-05-21 15:06:14   \n",
      "1399 2022-05-21 21:59:51  (nan, 202, 을지로입구) 2022-05-21 22:49:31   \n",
      "\n",
      "         OutInformation TransactionID TransferCount  \n",
      "588   (nan, 1208.0, 덕소)             1             1  \n",
      "1070   (nan, 415.0, 미아)             2             0  \n",
      "1164  (nan, 317.0, 경복궁)             1             0  \n",
      "1399  (nan, 1706.0, 안양)             2             0  \n",
      "\n",
      "377\n"
     ]
    }
   ],
   "source": [
    "print(df_2ndline_sorted[:4])\n",
    "print()\n",
    "print(len(set(df_2ndline_sorted['user_code'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "# ========= 환경/스키마 설정 =========\n",
    "data_dir  = may_path    # 탐색 루트 폴더\n",
    "day_start_str = \"20220501\"\n",
    "date_str  = \"TCD_20220501_train_final_part\"       # 분석 일자 (YYYY-MM-DD)\n",
    "pattern   = f\"{data_dir}/{date_str}*.npy\"  # 하위 폴더 포함 탐색\n",
    "\n",
    "day_start = pd.Timestamp(day_start_str)\n",
    "day_end = day_start + pd.Timedelta(days=1)\n",
    "\n",
    "def z4(x):  # 4자리 zero pad\n",
    "    return str(int(x)).zfill(4)\n",
    "\n",
    "def row_match_codes(val, codes:set[str]) -> bool:\n",
    "    \"\"\"\n",
    "    val: Transaction_code 한 행의 값 (예: '0201', 201, ('0201','XXXX') 등)\n",
    "    codes: 허용 코드 집합(문자열 4자리)\n",
    "    \"\"\"\n",
    "    # 시퀀스(튜플/리스트/ndarray 등)인 경우: 구성요소 중 하나라도 매칭되면 True\n",
    "    if isinstance(val, Iterable) and not isinstance(val, (bytes, bytearray)):\n",
    "        try:\n",
    "            for x in val:\n",
    "                if pd.isna(x):\n",
    "                    continue\n",
    "                if z4(x) in codes:\n",
    "                    return True\n",
    "            return False\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # 그 외 타입은 매칭 실패로 간주\n",
    "    return False\n",
    "\n",
    "def iter_day_files():\n",
    "    return sorted(glob.glob(pattern))\n",
    "\n",
    "# ========= 공통: 파일->DataFrame (부분 컬럼만) =========\n",
    "def load_part_df(npy_path, need_count=False):\n",
    "    data = np.load(npy_path, allow_pickle=True)\n",
    "    df = pd.DataFrame(data, columns=['user_code', 'Transaction_code', 'InTime','InInformation','OutTime','OutInformation','TransactionID', 'TransferCount'])\n",
    "\n",
    "    # 필요한 컬럼만 추출\n",
    "    # df_selected_line = df[(df['Transaction_code'].apply(lambda x: x[0] == 201))]\n",
    "\n",
    "    # np.datetime64 -> pandas datetime64[ns]\n",
    "    # (np.datetime64이면 to_datetime에서 손실 없이 처리됨)\n",
    "    df[\"InTime\"] = pd.to_datetime(df[\"InTime\"], errors=\"coerce\")\n",
    "    df[\"OutTime\"] = pd.to_datetime(df[\"OutTime\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ========= 1) 당일 고유 사용자 수 (옵션: 특정 호선만) =========\n",
    "def unique_users_in_day(line_id=None):\n",
    "    uniq = set()\n",
    "    for p in iter_day_files():\n",
    "        df = load_part_df(p, need_count=False)\n",
    "        if line_id is not None:\n",
    "            df = df[df['Transaction_code'].apply(lambda x: x[0] == 201)]\n",
    "            if line_id == 1:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_1)]\n",
    "            elif line_id == 2:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_2)]\n",
    "            elif line_id == 3:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_3)]\n",
    "            elif line_id == 4:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_4)]\n",
    "            else:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_9)]\n",
    "        if not df.empty:\n",
    "            uniq.update(df[\"user_code\"].unique().tolist())\n",
    "    return len(uniq)\n",
    "\n",
    "# ========= 2) 시간 버킷 집계 (이벤트 건수 or count 합) =========\n",
    "def time_bucket_counts(freq=\"H\", line_id=None):\n",
    "    \"\"\"\n",
    "    freq: 'H' | '30T' | '10T'\n",
    "    반환: DatetimeIndex (해당 일자 구간) 인덱스의 Series (int)\n",
    "    \"\"\"\n",
    "    total = None\n",
    "    for p in iter_day_files():\n",
    "        df = load_part_df(p)\n",
    "        if line_id is not None:\n",
    "            df = df[df['Transaction_code'].apply(lambda x: x[0] == 201)]\n",
    "            if line_id == 1:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_1)]\n",
    "            elif line_id == 2:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_2)]\n",
    "            elif line_id == 3:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_3)]\n",
    "            elif line_id == 4:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_4)]\n",
    "            else:\n",
    "                df = df[df['InInformation'].apply(lambda x: z4(x[1]) in line_9)]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df = df.set_index(\"InTime\")\n",
    "        part = df.resample(freq).size()              # 이벤트 건수\n",
    "\n",
    "        total = part if total is None else total.add(part, fill_value=0)\n",
    "\n",
    "    # 누락 구간 0 채우기 및 정렬\n",
    "    if total is None:\n",
    "        # 일자 전체 인덱스(빈 시리즈) 생성\n",
    "        full_idx = pd.date_range(day_start, day_end, freq=freq, inclusive=\"left\")\n",
    "        return pd.Series(0, index=full_idx, dtype=\"int64\")\n",
    "\n",
    "    full_idx = pd.date_range(day_start, day_end, freq=freq, inclusive=\"left\")\n",
    "    total = total.reindex(full_idx, fill_value=0).sort_index().astype(\"int64\")\n",
    "    return total\n",
    "\n",
    "# ================= 실행 예시 =================\n",
    "# # (A) 당일 전체/특정 호선 고유 이용자 수\n",
    "# all_users = unique_users_in_day(line_id=None)\n",
    "# line2_users = unique_users_in_day(line_id=2)\n",
    "\n",
    "# # (B) 1시간/30분/10분 버킷 집계 (이벤트 건수 기준)\n",
    "# by_1h_all  = time_bucket_counts(freq=\"h\",   line_id=None)\n",
    "# by_30m_all = time_bucket_counts(freq=\"30min\", line_id=None)\n",
    "# by_10m_all = time_bucket_counts(freq=\"10min\", line_id=None)\n",
    "\n",
    "# # (C) 특정 호선(예: 2호선)\n",
    "# by_1h_line2 = time_bucket_counts(freq=\"h\", line_id=2)\n",
    "\n",
    "# print(\"전체 고유 사용자 수:\", all_users)\n",
    "# print(\"2호선 고유 사용자 수:\", line2_users)\n",
    "# print(by_1h_all.head())\n",
    "# print(by_1h_line2.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db806466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections.abc import Iterable\n",
    "from matplotlib import font_manager, rcParams\n",
    "\n",
    "# ================= 기본 설정 =================\n",
    "may_path = os.path.join(os.getcwd(), \"202205\", \"train_pars_final_5\")\n",
    "root_path   = may_path                     # 전체 데이터 루트\n",
    "recursive   = False                        # 하위폴더까지면 True로, 패턴에 ** 추가됨\n",
    "out_dir     = os.path.join(root_path, \"plots\")\n",
    "target_lines = [2, None]       # None=전체집계 포함(원하면 수정)\n",
    "freqs = (\"1min\",) #(\"h\", \"30min\", \"10min\", \"1min\")            # 저장할 시간 버킷\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ---------------- (선택) 한글 폰트 ----------------\n",
    "def setup_korean_font():\n",
    "    candidates = ['Malgun Gothic','AppleGothic','NanumGothic','Noto Sans CJK KR','Noto Sans KR']\n",
    "    avail = {f.name for f in font_manager.fontManager.ttflist}\n",
    "    for c in candidates:\n",
    "        if c in avail:\n",
    "            rcParams['font.family'] = c\n",
    "            break\n",
    "    rcParams['axes.unicode_minus'] = False\n",
    "setup_korean_font()\n",
    "\n",
    "# ================ 라인 코드셋 ================\n",
    "def z4(x):  # 4자리 zero-pad\n",
    "    return str(int(x)).zfill(4)\n",
    "\n",
    "# 필요 시 직접 정의되어 있는 line_1~line_9 리스트를 아래처럼 정규화해서 set[str]로 사용\n",
    "# (이미 존재한다면 이 블록으로 교체/정규화 권장)\n",
    "# line_1 = {z4(n) for n in range(150, 160)}\n",
    "# line_2 = {z4(n) for n in range(201, 251)}\n",
    "# line_3 = {z4(n) for n in range(309, 343)}\n",
    "# line_4 = {z4(n) for n in range(409, 435)} | {\"0405\",\"0406\",\"0408\"}\n",
    "# line_9 = {z4(n) for n in range(4101, 4139)}  # 4101~4138 (201/205 혼재 구간 포함)\n",
    "LINE_CODESETS = {1: line_1, 2: line_2, 3: line_3, 4: line_4, 9: line_9}\n",
    "\n",
    "# ================ 파일 탐색/날짜 추출 ================\n",
    "def discover_dates(root_path:str, recursive:bool=False):\n",
    "    pat = os.path.join(root_path, \"**\", \"TCD_*_train_final_part*.npy\") if recursive \\\n",
    "          else os.path.join(root_path, \"TCD_*_train_final_part*.npy\")\n",
    "    files = glob.glob(pat, recursive=recursive)\n",
    "    rx = re.compile(r\"TCD_(\\d{8})_train_final_part\")\n",
    "    dates = set()\n",
    "    for p in files:\n",
    "        m = rx.search(os.path.basename(p))\n",
    "        if m: dates.add(m.group(1))\n",
    "    return sorted(dates)\n",
    "\n",
    "def iter_day_files(root_path:str, yyyymmdd:str, recursive:bool=False):\n",
    "    prefix = f\"TCD_{yyyymmdd}_train_final_part\"\n",
    "    pat = os.path.join(root_path, \"**\", f\"{prefix}*.npy\") if recursive \\\n",
    "          else os.path.join(root_path, f\"{prefix}*.npy\")\n",
    "    return sorted(glob.glob(pat, recursive=recursive))\n",
    "\n",
    "# ================ 안전 추출 함수 ================\n",
    "def get_mode_code(x):\n",
    "    \"\"\"교통수단 코드(201/205 등) - InInformation의 첫 요소로 가정.\"\"\"\n",
    "    try:\n",
    "        if isinstance(x, np.generic):\n",
    "            x = x.item()\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes, bytearray)):\n",
    "            it = iter(x)\n",
    "            return int(next(it))\n",
    "        return int(x)\n",
    "    except Exception: return None\n",
    "\n",
    "def get_line_code_str4(x):\n",
    "    \"\"\"노선 코드(예: '0201') - InInformation의 둘째 요소로 가정.\"\"\"\n",
    "    try:\n",
    "        if isinstance(x, np.generic): x = x.item()\n",
    "        if isinstance(x, Iterable) and not isinstance(x, (str, bytes, bytearray)):\n",
    "            it = iter(x)\n",
    "            next(it)          # 첫 요소 skip\n",
    "            second = next(it, None)\n",
    "            return z4(second) if second is not None and not pd.isna(second) else None\n",
    "        return z4(x)  # 비정상 스칼라 케이스 방어\n",
    "    except Exception: return None\n",
    "\n",
    "# ================ 로딩/필터/집계 ================\n",
    "def load_part_df(npy_path:str, day_start:pd.Timestamp):\n",
    "    data = np.load(npy_path, allow_pickle=True)   # object dtype이라 mmap 불가\n",
    "    df = pd.DataFrame(\n",
    "        data,\n",
    "        columns=['user_code','Transaction_code','InTime','InInformation',\n",
    "                 'OutTime','OutInformation','TransactionID','TransferCount']\n",
    "    )\n",
    "    df[\"InTime\"] = pd.to_datetime(df[\"InTime\"], errors=\"coerce\")\n",
    "    day_end = day_start + pd.Timedelta(days=1)\n",
    "    df = df[(df[\"InTime\"] >= day_start) & (df[\"InTime\"] < day_end)]\n",
    "    return df[[\"user_code\",'Transaction_code',\"InInformation\",\"InTime\"]]\n",
    "\n",
    "def filter_by_line(df:pd.DataFrame, line_id:int|None):\n",
    "    if line_id is None:\n",
    "        return df\n",
    "    allowed_modes = {201, 205} if line_id == 9 else {201}\n",
    "    df = df[df[\"Transaction_code\"].apply(lambda v: get_mode_code(v) in allowed_modes)]\n",
    "    codes = LINE_CODESETS[line_id]\n",
    "    df = df[df[\"InInformation\"].apply(lambda v: (c := get_line_code_str4(v)) is not None and c in codes)]\n",
    "    return df\n",
    "\n",
    "def unique_users_in_day(root_path:str, yyyymmdd:str, line_id:int|None):\n",
    "    day_start = pd.Timestamp(yyyymmdd)\n",
    "    uniq = set()\n",
    "    for p in iter_day_files(root_path, yyyymmdd, recursive):\n",
    "        df = load_part_df(p, day_start)\n",
    "        if df.empty: continue\n",
    "        df = filter_by_line(df, line_id)\n",
    "        if df.empty: continue\n",
    "        uniq.update(df[\"user_code\"].unique().tolist())\n",
    "    return len(uniq)\n",
    "\n",
    "def time_bucket_counts(root_path:str, yyyymmdd:str, freq:str, line_id:int|None):\n",
    "    \"\"\"freq: 'h' | '30min' | '10min'\"\"\"\n",
    "    day_start = pd.Timestamp(yyyymmdd)\n",
    "    total = None\n",
    "    for p in iter_day_files(root_path, yyyymmdd, recursive):\n",
    "        df = load_part_df(p, day_start)\n",
    "        if df.empty: continue\n",
    "        df = filter_by_line(df, line_id)\n",
    "        if df.empty: continue\n",
    "        s = (df.set_index(\"InTime\").resample(freq).size().astype(\"int64\"))\n",
    "        total = s if total is None else total.add(s, fill_value=0)\n",
    "    full_idx = pd.date_range(day_start, day_start + pd.Timedelta(days=1), freq=freq, inclusive=\"left\")\n",
    "    if total is None:\n",
    "        return pd.Series(0, index=full_idx, dtype=\"int64\")\n",
    "    return total.reindex(full_idx, fill_value=0).sort_index().astype(\"int64\")\n",
    "\n",
    "# ================ 플로팅 ================\n",
    "def save_time_series_plot(series:pd.Series, title:str, outpath:str,\n",
    "                          xmin:pd.Timestamp, xmax:pd.Timestamp):\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.plot(series.index, series.values, marker='o')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Usage Count\")\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    locator = mdates.AutoDateLocator(minticks=8, maxticks=12)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def save_daily_plot(daily_series:pd.Series, title:str, outpath:str):\n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.plot(daily_series.index, daily_series.values, marker='o')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Unique Users\")\n",
    "    locator = mdates.AutoDateLocator(minticks=6, maxticks=10)\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outpath, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def line_label(line_id:int|None):\n",
    "    return \"all\" if line_id is None else f\"line{line_id}\"\n",
    "\n",
    "# ================ 메인 루프 ================\n",
    "def process_all_days():\n",
    "    dates = discover_dates(root_path, recursive)\n",
    "    if not dates:\n",
    "        raise RuntimeError(\"No dates found. Please check file name pattern/path.\")\n",
    "\n",
    "    for line_id in target_lines:\n",
    "        # --- 1) 일자별 고유 사용자 수 집계/저장 ---\n",
    "        # day_vals = []\n",
    "        # for d in dates:\n",
    "        #     cnt = unique_users_in_day(root_path, d, line_id)\n",
    "        #     day_vals.append((pd.Timestamp(d), cnt))\n",
    "        #     print(f\"[{line_label(line_id)}] {d} unique_users = {cnt}\")\n",
    "\n",
    "        # daily_series = pd.Series(\n",
    "        #     [v for _, v in day_vals],\n",
    "        #     index=[t for t, _ in day_vals],\n",
    "        #     name=\"unique_users\"\n",
    "        # ).sort_index()\n",
    "\n",
    "        subdir = os.path.join(out_dir, line_label(line_id))\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "        # # 그래프 + CSV 저장\n",
    "        # save_daily_plot(daily_series,\n",
    "        #                 f\"Daily Unique Users ({line_label(line_id)})\",\n",
    "        #                 os.path.join(subdir, f\"{line_label(line_id)}_daily_unique.png\"))\n",
    "        # daily_series.to_csv(os.path.join(subdir, f\"{line_label(line_id)}_daily_unique.csv\"),\n",
    "        #                     index_label=\"date\")\n",
    "\n",
    "        # --- 2) 각 날짜별 시간대 그래프 저장 ---\n",
    "        for d in dates:\n",
    "            day_start = pd.Timestamp(d)\n",
    "            for f in freqs:\n",
    "                s = time_bucket_counts(root_path, d, f, line_id)\n",
    "                ftag = {\"h\":\"1hour\",\"30min\":\"30min\",\"10min\":\"10min\",\"1min\":\"1min\"}[f]\n",
    "                subdir_f = os.path.join(subdir, f)       # plots/lineX/h or 30min or 10min\n",
    "                os.makedirs(subdir_f, exist_ok=True)\n",
    "                save_time_series_plot(\n",
    "                    s,\n",
    "                    f\"{line_label(line_id)} time series ({d}, {ftag})\",\n",
    "                    os.path.join(subdir_f, f\"{line_label(line_id)}_{d}_{ftag}.png\"),\n",
    "                    day_start, day_start + pd.Timedelta(days=1)\n",
    "                )\n",
    "                # (선택) 데이터도 저장\n",
    "                s.to_csv(os.path.join(subdir_f, f\"{line_label(line_id)}_{d}_{ftag}.csv\"),\n",
    "                         header=[\"count\"])\n",
    "    print(f\"Done: output directory = {out_dir}\")\n",
    "\n",
    "# 실행\n",
    "# process_all_days()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac6fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등록된 나눔 폰트: ['NanumGothic']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "FONT_PATH = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "\n",
    "# 1) 폰트 파일을 Matplotlib에 명시적으로 등록\n",
    "fm.fontManager.addfont(FONT_PATH)\n",
    "\n",
    "# 2) 폰트 매니저 캐시를 프로세스 내에서 강제 리로드\n",
    "fm._load_fontmanager(try_read_cache=False)\n",
    "\n",
    "# 3) 전역 폰트 설정 (가급적 family 이름을 문자열로 직접 지정)\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothic'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['NanumGothic']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False  # 마이너스 깨짐 방지\n",
    "\n",
    "print(\"등록된 나눔 폰트:\",\n",
    "      [f.name for f in fm.fontManager.ttflist if 'Nanum' in f.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: output directory = /home/data/202205/train_pars_final_5/plots\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# 특정호선 역별로 처리하는 것\n",
    "###############\n",
    "\n",
    "def sanitize_filename(s: str) -> str:\n",
    "    \"\"\"역명으로 폴더/파일명 만들 때 안전하게 정제\"\"\"\n",
    "    s = re.sub(r\"[\\\\/:*?\\\"<>|]\", \"_\", s)\n",
    "    s = s.replace(\" \", \"\")  # 가독성을 위해 공백 제거(원하면 유지)\n",
    "    return s\n",
    "\n",
    "def time_bucket_counts_by_station(root_path: str, yyyymmdd: str, freq: str, line_id: int = 2\n",
    "                                 ) -> Dict[str, pd.Series]:\n",
    "    \"\"\"\n",
    "    주어진 날짜(yyyymmdd)에 대해 2호선의 역별 시간 버킷 카운트를 반환.\n",
    "    return: {역명 -> Series(count, index=pd.DatetimeIndex)}\n",
    "    \"\"\"\n",
    "    assert line_id == 2, \"이 함수는 2호선 전용입니다.\"\n",
    "    day_start = pd.Timestamp(yyyymmdd)\n",
    "    full_idx = pd.date_range(day_start, day_start + pd.Timedelta(days=1), freq=freq, inclusive=\"left\")\n",
    "\n",
    "    totals: Dict[str, pd.Series] = {}  # 역명 -> series 누적\n",
    "\n",
    "    for p in iter_day_files(root_path, yyyymmdd, recursive):\n",
    "        df = load_part_df(p, day_start)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df = filter_by_line(df, line_id)\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # InInformation → 4자리 코드 → 역명\n",
    "        # (성능을 위해 벡터화: apply 한 번으로 code 추출 후 map)\n",
    "        codes = df[\"InInformation\"].apply(get_line_code_str4)\n",
    "        names = codes.map(lambda c: code_to_station.get(c, \"<UNKNOWN>\"))\n",
    "\n",
    "        tmp = df.assign(station_name=names).dropna(subset=[\"InTime\"])\n",
    "        if tmp.empty:\n",
    "            continue\n",
    "\n",
    "        # 역별로 나눠 resample\n",
    "        tmp = tmp.set_index(\"InTime\")\n",
    "        for stn, grp in tmp.groupby(\"station_name\"):\n",
    "            s = grp.resample(freq).size().astype(\"int64\")\n",
    "            s = s.reindex(full_idx, fill_value=0).sort_index().astype(\"int64\")\n",
    "            if stn in totals:\n",
    "                totals[stn] = totals[stn].add(s, fill_value=0).astype(\"int64\")\n",
    "            else:\n",
    "                totals[stn] = s\n",
    "\n",
    "    # 데이터가 하나도 없었을 경우 대비: 모든 2호선 역에 대해 0 시리즈를 채워줌\n",
    "    for stn in names_line_2:\n",
    "        if stn not in totals:\n",
    "            totals[stn] = pd.Series(0, index=full_idx, dtype=\"int64\")\n",
    "\n",
    "    return totals\n",
    "\n",
    "\n",
    "# === 메인 루프 교체: 2호선 각 역별 플롯/CSV 저장 =============================\n",
    "def process_line2_station_timeseries():\n",
    "    dates = discover_dates(root_path, recursive)\n",
    "    if not dates:\n",
    "        raise RuntimeError(\"No dates found. Please check file name pattern/path.\")\n",
    "\n",
    "    # 출력 폴더: plots/line2/<freq>/<역명>\n",
    "    base_subdir = os.path.join(out_dir, \"line2\")\n",
    "    os.makedirs(base_subdir, exist_ok=True)\n",
    "\n",
    "    for d in dates:\n",
    "        day_start = pd.Timestamp(d)\n",
    "        for f in freqs:\n",
    "            totals = time_bucket_counts_by_station(root_path, d, f, line_id=2)\n",
    "\n",
    "            ftag = {\"h\":\"1hour\",\"30min\":\"30min\",\"10min\":\"10min\",\"1min\":\"1min\"}[f]\n",
    "            subdir_f = os.path.join(base_subdir, f, \"subway\")\n",
    "            os.makedirs(subdir_f, exist_ok=True)\n",
    "\n",
    "            # 역별 저장\n",
    "            for stn, s in totals.items():\n",
    "                stn_safe = sanitize_filename(stn)\n",
    "                stn_dir = os.path.join(subdir_f, stn_safe)\n",
    "                os.makedirs(stn_dir, exist_ok=True)\n",
    "\n",
    "                png_path = os.path.join(stn_dir, f\"line2_{stn_safe}_{d}_{ftag}.png\")\n",
    "                csv_path = os.path.join(stn_dir, f\"line2_{stn_safe}_{d}_{ftag}.csv\")\n",
    "\n",
    "                save_time_series_plot(\n",
    "                    s,\n",
    "                    f\"2호선 {stn} 역 이용 추이 ({d}, {ftag})\",\n",
    "                    png_path,\n",
    "                    day_start, day_start + pd.Timedelta(days=1)\n",
    "                )\n",
    "                s.to_csv(csv_path, header=[\"count\"])\n",
    "\n",
    "    print(f\"Done: output directory = {out_dir}\")\n",
    "\n",
    "# === 실행 진입점: 기존 process_all_days() 대신 아래 함수 호출 ==================\n",
    "process_line2_station_timeseries()\n",
    "# === 추가/교체 코드 끝 ======================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T_money",
   "language": "python",
   "name": "t_money"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
